{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install --upgrade tensorflow==2.12.0\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder = tf.keras.saving.load_model(\"../app/model/AEv3encoder3seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               3276900   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,370,148\n",
      "Trainable params: 3,370,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_melspectrogram(y: np.ndarray, sr: int, output_file: str, array_path: str = None):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            y : np.ndarray [shape=(..., n)] or None\n",
    "                audio time-series. Multi-channel is supported.\n",
    "            sr : number > 0 [scalar]\n",
    "                sampling rate of ``y``\n",
    "            output_file: str or pathlib.Path\n",
    "                file to store the diagram\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.dirname(output_file)):\n",
    "      os.makedirs(os.path.dirname(output_file))\n",
    "\n",
    "    melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512)\n",
    "\n",
    "    mel = librosa.power_to_db(melspectrogram_array)\n",
    "    # Length and Width of Spectogram\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = float(mel.shape[1] / 100)\n",
    "    fig_size[1] = float(mel.shape[0] / 100)\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.axis('off')\n",
    "    plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n",
    "    librosa.display.specshow(mel)   # ,cmap='gray_r'\n",
    "    plt.savefig(output_file, dpi=100)\n",
    "    plt.close()\n",
    "    if array_path is not None:\n",
    "      np.save(array_path, melspectrogram_array)\n",
    "    return melspectrogram_array, output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_image(image, new_width, new_height):\n",
    "#     # Resize the image\n",
    "#     resized_image = cv2.resize(image, (new_width, new_height, 3), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#     # Save the resized image\n",
    "#     return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(audio_path: str, encoder_model):\n",
    "\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # if file shorter than 30 seconds, padding with zeros\n",
    "    if len(y)//sr < 30:\n",
    "      new_array_30_secs = np.zeros(sr*30)\n",
    "      new_array_30_secs[:len(y)] = y\n",
    "    else:\n",
    "      # extract middle 30 seconds of file\n",
    "      middle = len(y)//2\n",
    "      start = middle - int(sr*15)\n",
    "      end = middle + int(sr*15)\n",
    "      new_array_30_secs = y[start:end]\n",
    "\n",
    "    melspectrogram, output_file = create_melspectrogram(new_array_30_secs, sr, \"/tmp/melspectrogram.jpg\")\n",
    "    melspectrogram_resized = cv2.imread(output_file)[:, :1280, :]\n",
    "    # return melspectrogram_resized\n",
    "    predictions = []\n",
    "    \n",
    "    for counter in range(10):\n",
    "      predictions.extend(encoder_model.predict(melspectrogram_resized[: , counter*128:(counter+1)*128, :].reshape(-1, 128, 128, 3)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofile = \"../data/80x27s-islandy-loop-925bpm-132431.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "test = predict_audio(audiofile, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
