{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofile = \"../data/kingslayer.mp3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Audio inside Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audiofile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spectrogram\n",
    "\n",
    "**Sampling**\n",
    "\n",
    "Sound is a continuous wave. We can digitise sound by breaking the continuous wave into discrete signals. This process is called sampling. Sampling converts a sound wave into a sequence of samples or a discrete-time signal.\n",
    "\n",
    "The load functions loads the audio file and converts it into an array of values which represent the amplitude if a sample at a given point of time.\n",
    "\n",
    "**Sampling Rate**\n",
    "\n",
    "The sampling rate is the number of samples per second. Hz or Hertz is the unit of the sampling rate. 20 kHz is the audible range for human beings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sr = librosa.load(audiofile)#, sr=22050, mono=True, offset=0.0, duration=50, res_type='kaiser_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "librosa.display.waveshow(data,sr=sr, max_points=5000, axis='time', transpose=False)\n",
    "# plt.xlim(0,10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## librosa beat extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofile = librosa.example('nutcracker')\n",
    "\n",
    "y, sr = librosa.load(audiofile)\n",
    "\n",
    "# Run the default beat tracker\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "print('Estimated tempo: {:.2f} beats per minute'.format(tempo))\n",
    "\n",
    "# Convert the frame indices of beat events into timestamps\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_len = len(y) / sr\n",
    "timestamps = np.linspace(0, audio_len, num=len(y))\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(timestamps, y)\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(20, 30)\n",
    "plt.vlines([beat_times], ymin=-0.5, ymax=0.5, linestyles=\"dashed\", colors=\"black\", linewidth=0.5)\n",
    "plt.title(\"Beat Tracker Example: Nutcracker\")\n",
    "# plt.savefig(\"beat_extraction_sample.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
